{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment — Link prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import requests\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. Dataset for link prediction (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-j6Lpn03K98"
   },
   "source": [
    "Consider link prediction on the [e-mails network](http://snap.stanford.edu/data/email-Eu-core-temporal.html) where nodes are members of a research institution and edges are e-mails given with timestamps. The goal is to predict occurrence of edges in the test time period using information from the train time period only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RV1M-w9L3K99"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/netspractice/network-science/main/datasets/email-Eu-core-temporal.txt'\n",
    "open('email-Eu-core-temporal.txt', 'wb').write(requests.get(url).content);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "3UBncA5d3K99",
    "outputId": "b2a01072-204a-4278-af2f-f56f5df97fa5"
   },
   "outputs": [],
   "source": [
    "email_df = pd.read_csv(\n",
    "    'email-Eu-core-temporal.txt', \n",
    "    delimiter=' ', \n",
    "    names=['sender', 'receiver', 'timestamp']\n",
    ")\n",
    "email_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdjk0oKL3K9_"
   },
   "source": [
    "Next, consider the following preprocessing procedure:\n",
    "1. Select edges by given train and test time periods, for example, [0, 1000) is train and [1000, 2000) is test\n",
    "2. Build a _core_ — a connected network where every edge occurs at least $k_\\text{train}$ times in the train time period or at least $k_\\text{test}$ times in the test time period. Let the core be undirected, so occurrences edges (1, 0) and (0, 1) are computed together.\n",
    "3. From the core, select a train set of edges $E_\\text{train}$ that occur for the first time in the train period. All others are included to $E_\\text{test}$.\n",
    "3. Exclude test edges that contain nodes that do not occur in train edges.\n",
    "\n",
    "Write a function `train_test_edges` that takes a pd.DataFrame `email_df` with e-mail network, a tuple with the train time period borders `train_period`, say, (0, 1000), a similar tuple `test_period`, the number of edges occurrences `ktrain` and `ktest`. The function returns two lists with tuples — train and test edges. Every edge is returned of the form where the first node is less than the second, for example [(1, 2), (2, 3)] is ok, but [(2, 1), (3, 2)] is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "WOtzLBpV3K-A",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d02465886cf63caec30af195db4cf5b9",
     "grade": false,
     "grade_id": "cell-676bd18fcab3c342",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_test_edges(email_df, train_period, test_period, ktrain, ktest):\n",
    "    \n",
    "    email_temp = email_df.copy()\n",
    "    email_temp = email_temp[\n",
    "        (train_period[0] <= email_temp.timestamp) \n",
    "        & (email_temp.timestamp < test_period[1])\n",
    "    ]\n",
    "    email_temp['from'] = email_temp[['sender', 'receiver']].min(axis=1)\n",
    "    email_temp['to'] = email_temp[['sender', 'receiver']].max(axis=1)\n",
    "    email_temp = email_temp.drop(['sender', 'receiver'], axis=1)\n",
    "    email_temp = email_temp.set_index(['from', 'to'])\n",
    "\n",
    "    email_train = email_temp[email_temp.timestamp < train_period[1]]\n",
    "    email_train = email_train.groupby(['from', 'to']).count()\n",
    "    train_core = email_train[email_train.timestamp >= ktrain].index.tolist()\n",
    "\n",
    "    email_test = email_temp[test_period[0] <= email_temp.timestamp]\n",
    "    email_test = email_test.groupby(['from', 'to']).count()\n",
    "    test_core = email_test[email_test.timestamp >= ktest].index.tolist()\n",
    "    \n",
    "    core = list(set(train_core + test_core))\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xtl9IT4V3K-B",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e621b7732445421269c1fb314cd20f3",
     "grade": true,
     "grade_id": "cell-a77f2fa764e87595",
     "locked": true,
     "points": 2.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_pos, test_pos = train_test_edges(email_df, (1e7, 2e7), (2e7, 2.5e7), 4, 2)\n",
    "_train_pos, _test_pos = np.array(train_pos), np.array(test_pos)\n",
    "assert np.all(_train_pos[:, 0] < _train_pos[:, 1])\n",
    "assert np.all(_test_pos[:, 0] < _test_pos[:, 1])\n",
    "assert len(set(train_pos).intersection(test_pos)) == 0\n",
    "assert _train_pos.shape == (3880, 2)\n",
    "assert _test_pos.shape == (720, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. Negative sampling (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycOjaWsk3K-D"
   },
   "source": [
    "Usually, graphs are sparse, so there is the high imbalance between existent (positive) edges and nonexistent (negative) edges. Since the link prediction can be considered as a classification problem, the imbalance leads to the high misclassification. To eliminate this problem, we can use the negative sampling techniques, that is using only a some random part of negative edges in training.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/netspractice/network-science/main/images/pos_neg_edges.png' width=500>\n",
    "\n",
    "The simplest sampling strategy is to copy positive edges and randomly replace one node checking they do not occur in positive set and they are not self-loops. Let the negative set be the same size as the positive.\n",
    "\n",
    "The `negative_sampling` function samples the unexisted edges from the graph. It takes list of train and test positive edges and returns train and test negative edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "I85ekK3u3K-D",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "909994f38bc19f1e40c34bd32036ba50",
     "grade": false,
     "grade_id": "cell-2086061e022dc394",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def negative_sampling(train_pos, test_pos):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "0cced4d871564e8db7b8295a73a28d68",
      "17fa61f4ff0b46b9be276e408fa28e9d",
      "94f4745ef9ae489998f6103e00dfa3db",
      "cab500e00ae944bd8ac04fd54e8ad4e6",
      "b1ada846cad14d35994d6a84526a69c8",
      "832905f0361140a6b0b4b5612ad09085",
      "d906d704ee104f6a9cda9e0642cfa5fb",
      "1ea52339ba184d8f815849c5ee73c422",
      "e0a642b90ada43cf876d20d116cbbadd",
      "2d1d425d033e46d08f5e8f2d00b72145",
      "3bb0d394d5f64dffab946bb87f0aeaa3"
     ]
    },
    "deletable": false,
    "editable": false,
    "id": "ZHEKYONa3K-E",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c349f53d7c0142468245b819330d251",
     "grade": true,
     "grade_id": "cell-e71e5d52cb2cae88",
     "locked": true,
     "points": 2.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "dad996e9-486b-40f6-cd7d-7ee11ba692e1"
   },
   "outputs": [],
   "source": [
    "train_neg, test_neg = negative_sampling(train_pos, test_pos)\n",
    "neg_edges = train_neg + test_neg\n",
    "pos_edges = train_pos + test_pos\n",
    "assert len(train_neg) == len(train_pos)\n",
    "assert len(test_neg) == len(test_neg)\n",
    "# negative edges has nodes from only positive edges\n",
    "assert len(set(np.unique(neg_edges)).difference(np.unique(pos_edges))) == 0\n",
    "# source nodes are the same\n",
    "assert np.all(np.array(pos_edges)[:, 0] == np.array(neg_edges)[:, 0])\n",
    "# no edges in both\n",
    "assert len(set(pos_edges) & set(neg_edges)) == 0\n",
    "# reversed negative edges are not positive\n",
    "reversed_neg_edges = [(v, u) for u, v in neg_edges]\n",
    "assert len(set(pos_edges) & set(reversed_neg_edges)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUZJSmH43K-E"
   },
   "source": [
    "Form train and test pairs of nodes that contain positive and negative edges:\n",
    "* $X_\\text{train}, X_\\text{test}$ — pairs of nodes, contains positive and negative edges\n",
    "* $y_\\text{train}, y_\\text{test}$ — labels of pairs, 1 is positive, 0 is negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TeUE20TO3K-F",
    "outputId": "6fc5c485-c73f-45db-d173-f9d29bfd1a94"
   },
   "outputs": [],
   "source": [
    "x_train = np.random.permutation(train_pos + train_neg)\n",
    "y_train = [int((u, v) in train_pos) for (u, v) in x_train]\n",
    "\n",
    "x_test = np.random.permutation(test_pos + test_neg)\n",
    "y_test = [int((u, v) in test_pos) for (u, v) in x_test]\n",
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. Prediction by similarity score (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khMqP2le3K-F"
   },
   "source": [
    "Similarity based algorithm predicts the existence of a link using the similarity score of a pair of nodes: $P(A_{i, j}) \\propto \\text{sim}(i, j)$. The algorithm builds a graph using only train positive edges, compute similarity score for all test pairs and then predicts the link existence by the threshold on ordered by similarity score pairs.\n",
    "\n",
    "Write a function `sim_link_prediction` that takes edges and labels. The function predicts links and returns a tuple with metrics: \n",
    "* FPR (false positive rate) and TPR (true positive rate) in descending of thresholds obtained by Jaccard coefficient, `nx.jaccard_coefficient`: $$\\text{sim}(i, j) = \\frac{|N(i) \\cap N(j)|}{|N(i) \\cup N(j)|}$$\n",
    "* FPR, TPR by Adamic-Adar index, `nx.adamic_adar_index`: $$\\text{sim}(i, j) = \\sum_{x \\in N(i) \\cap N(j)} \\frac{1}{\\log|N(x)|}$$\n",
    "* FPR, TPR by resource allocation index, `nx.resource_allocation_index`: $$\\text{sim}(i, j) = \\sum_{x \\in N(i) \\cap N(j)} \\frac{1}{|N(x)|}$$\n",
    "\n",
    "_Hint: use `sklearn.metrics.roc_curve`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "mMc429-f3K-G",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32af6091446052edf14c97545c0e6da2",
     "grade": false,
     "grade_id": "cell-4125af6f7f2c4f56",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sim_link_prediction(train_pos, x_test, y_test):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Olu-c1D63K-G",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd65e665b136e258223e2ba71397605b",
     "grade": true,
     "grade_id": "cell-ea34274053a92113",
     "locked": true,
     "points": 2.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "jac, adam, res = sim_link_prediction(\n",
    "    train_pos, \n",
    "    [[53, 500], [500, 843], [509, 969], [40, 91], [147, 28], [91, 535], [890, 15]],\n",
    "    [1, 0, 1, 0, 0, 1, 0],\n",
    ")\n",
    "assert jac[0].shape == jac[1].shape\n",
    "assert adam[0].shape == adam[1].shape\n",
    "assert res[0].shape == res[1].shape\n",
    "assert round(auc(jac[0], jac[1]), 4) == 0.5\n",
    "assert round(auc(adam[0], adam[1]), 4) == 0.4167\n",
    "assert round(auc(res[0], res[1]), 4) == 0.4167"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4T2Kwcl3K-G"
   },
   "source": [
    "Let us look at the ROC AUC curve to compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "PYjpeOSV3K-H",
    "outputId": "8392ab61-5274-4868-d0b5-561d0b930cf2"
   },
   "outputs": [],
   "source": [
    "jac, adam, res = sim_link_prediction(train_pos, x_test, y_test)\n",
    "plt.figure(figsize=(10, 6))\n",
    "cases = [[jac[0], jac[1], 'Jaccard'], \n",
    "         [adam[0], adam[1], 'Adamic-Adar'], \n",
    "         [res[0], res[1], 'Resource alloc.']]\n",
    "for fpr, tpr, label in cases:\n",
    "    plt.plot(fpr, tpr, lw=2, \n",
    "             label='{}, AUC={:.4f}'.format(label, auc(fpr, tpr)))\n",
    "plt.plot([0, 1], [0, 1], lw=2, linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4. Dot product predictor on node embeddings (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygThWA843K-H"
   },
   "source": [
    "Similarly to the node classification task, node embeddings could be helpful in the link prediction problem. We can predict a link if two nodes are similar in latent space. One of simple methods to obtain similarity score is using dot product of node embeddings: $$P(A_{i, j}) \\propto \\langle e_i, e_j \\rangle.$$\n",
    "\n",
    "Here we obtain 16d SVD node embeddings by `sklearn.decompose.TruncatedSVD` on the adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3j5n7_om3K-I",
    "outputId": "0e5c45c7-175e-4f89-b721-1efdcec65555"
   },
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(np.max(train_pos) + 1))\n",
    "G.add_edges_from(train_pos)\n",
    "A = nx.to_numpy_array(G)\n",
    "model = TruncatedSVD(n_components=16)\n",
    "emb = model.fit_transform(A)\n",
    "emb.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ku01Bi-53K-I"
   },
   "source": [
    "Write a function `dot_product_prediction` that takes node embeddings, test pairs, returns FPR and TPR for the test pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "GTO6K-TO3K-I",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2a9a90393f4821ede00fb251e579dfd",
     "grade": false,
     "grade_id": "cell-e3728903f481eed8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dot_product_prediction(emb, x_test, y_test):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "bK4iP3nU3K-I",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28109736ae59ebeb5d232aac6416e6d7",
     "grade": true,
     "grade_id": "cell-d7b6b9f3c20abc71",
     "locked": true,
     "points": 2.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fpr, tpr = dot_product_prediction(np.random.random(emb.shape), x_test, y_test)\n",
    "assert 0.45 < auc(fpr, tpr) < 0.55\n",
    "fpr, tpr = dot_product_prediction(emb, x_test, y_test)\n",
    "assert 0.75 < auc(fpr, tpr) < 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "OITz_G1p3K-J",
    "outputId": "f3acd8d8-0a00-40f3-ea25-e9a8e1caa705"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, lw=2, \n",
    "         label='{}, AUC={:.4f}'.format('Dot prod. on SVD emb.', auc(fpr, tpr)))\n",
    "plt.plot([0, 1], [0, 1], lw=2, linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5. Classification on edge emdeddings (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpflXtvt3K-J"
   },
   "source": [
    "Edge emeddings can be used for edge classification by any supervised algorithm (e.g. logistic regression). We can compute edge embeddings using embeddings of adjacent nodes. Let us compare several techniques of a such calculation from the paper: *Makarov I, Gerasimova O, Sulimov P, Zhukov LE. 2019. Dual network embedding for representing research interests in the link prediction problem on co-authorship networks*. Let us use SVD node embeddings for calculating edge embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_GS4A6L3K-J",
    "outputId": "477b62d9-fe30-4601-d3cd-5b714d4a372b"
   },
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(np.max(train_pos) + 1))\n",
    "G.add_edges_from(train_pos)\n",
    "A = nx.to_numpy_array(G)\n",
    "model = TruncatedSVD(n_components=4, random_state=0)\n",
    "emb = model.fit_transform(A)\n",
    "emb.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eftkuSkg3K-K"
   },
   "source": [
    "All following functions return edge embeddings for given graph, node embeddings, edges. Average operator is the elementwise average of node embeddings. \n",
    "$$\n",
    "\\frac{f(u)+f(v)}{2}\n",
    "$$\n",
    "where $f(u)$, $f(v)$ are node embeddings of nodes $u$ and $v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "NRWbyl-t3K-K",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58f462d94128ad39168d5c1651115bbc",
     "grade": false,
     "grade_id": "cell-26173c0c479136b7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def average_operator(G, embeddings, edges):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "rxNYOmnM3K-K",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c871d4517c493614d9d68da9c4a2d4b7",
     "grade": true,
     "grade_id": "cell-eaefe9963be3c2d0",
     "locked": true,
     "points": 0.29,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(\n",
    "    average_operator(G, emb, np.array([[42,70]])).round(1),\n",
    "    [[ 0.6, -0.2, -0.3, -0.2]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMJ11_b83K-K"
   },
   "source": [
    "Hadamard product is the elementwise product of node embeddings $$f(u) \\odot f(v)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "wIXD6FBw3K-L",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dca0930cdead56210ac1d3ed38a1da2d",
     "grade": false,
     "grade_id": "cell-f662abe3d0579575",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def hadamard_operator(G, embeddings, edges):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "eeW9uqZ03K-L",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "531a3fe4a1f68ca0a7befa1ad381a0e9",
     "grade": true,
     "grade_id": "cell-db04660af550adc7",
     "locked": true,
     "points": 0.29,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(\n",
    "    hadamard_operator(G, emb, np.array([[42,70]])).round(2),\n",
    "    [[0.21, 0.02, 0.09, 0.02]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXouLM733K-L"
   },
   "source": [
    "Weighted L1 is the absolute elementwise difference between node embeddings $$\n",
    "\\left|f(u)-f(v)\\right|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "yvyRYGfg3K-L",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6257c4c2eb4680600acc5867ddba862",
     "grade": false,
     "grade_id": "cell-5e44fbdf6a64715d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def weighted_l1_operator(G, embeddings, edges):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7EmL5V-v3K-M",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ef2e755e7452008bb8dc28362a2528f",
     "grade": true,
     "grade_id": "cell-f2c7878af729fcb5",
     "locked": true,
     "points": 0.29,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(\n",
    "    weighted_l1_operator(G, emb, np.array([[42,70]])).round(2),\n",
    "    [[0.88, 0.12, 0.28, 0.17]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqHW52fK3K-M"
   },
   "source": [
    "Weighted L2 is the squared elementwise difference between node embeddings $$\n",
    "\\left(f(u)-f(v)\\right)^{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "KAnCPzPt3K-M",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c81ca1cb9941e2216cb755dcb6b1d6df",
     "grade": false,
     "grade_id": "cell-0f7f5b3663337374",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def weighted_l2_operator(G, embeddings, edges):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xp9w2Arx3K-M",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42ac989e435cf1d61b24c64558451c06",
     "grade": true,
     "grade_id": "cell-957e1faea3e9127d",
     "locked": true,
     "points": 0.29,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(\n",
    "    weighted_l2_operator(G, emb, np.array([[42,70]])).round(2),\n",
    "    [[0.77, 0.01, 0.08, 0.03]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lo3bJTu3K-N"
   },
   "source": [
    "Neighbor weighted L1 is the absolute elementwise difference between mean embeddings of nodes neigbors $$\n",
    "\\left|\\frac{\\sum_{w \\in N(u) \\cup\\{u\\}} f(w)}{|N(u)|+1}-\\frac{\\sum_{t \\in N(v) \\cup\\{v\\}} f(t)}{|N(v)|+1}\\right|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "8FNs6X_d3K-N",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91862e3967ecf48894e45a0adf8af354",
     "grade": false,
     "grade_id": "cell-9663ec4df9dbb751",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def neighbor_weighted_l1_operator(G, embeddings, edges):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_DITuFV73K-N",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac5c283d4d99ef24ca9d11e9c7fb9180",
     "grade": true,
     "grade_id": "cell-fe7f124fa265373c",
     "locked": true,
     "points": 0.29,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(\n",
    "    neighbor_weighted_l1_operator(G, emb, np.array([[42,70]])).round(2),\n",
    "    [[1.89, 0.14, 0.3 , 0.18]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjrYTU7S3K-N"
   },
   "source": [
    "Neighbor weighted L2 is the squared elementwise difference between mean embeddings of nodes neigbors\n",
    "$$\n",
    "\\left(\\frac{\\sum_{w \\in N(u) \\cup\\{u\\}} f(w)}{|N(u)|+1}-\\frac{\\sum_{t \\in N(v) \\cup\\{v\\}} f(t)}{|N(v)|+1}\\right)^{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "fjoXpQPm3K-O",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fe87475999a79b39066260f060f80ca",
     "grade": false,
     "grade_id": "cell-cb55782d381636cd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def neighbor_weighted_l2_operator(G, embeddings, edges):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ZjodsRuH3K-O",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "163ff93c401ba467fe6baf21a3ec1752",
     "grade": true,
     "grade_id": "cell-b3ea740a7d8e7422",
     "locked": true,
     "points": 0.29,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(\n",
    "    neighbor_weighted_l2_operator(G, emb, np.array([[42,70]])).round(2),\n",
    "    [[3.58, 0.02, 0.09, 0.03]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brYnvdtAP5ww"
   },
   "source": [
    "Now let us look at the ROC AUC for different operators on 16d SVD nome embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ilk6IipN3K-O",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd07953ff85d4a893f48b1dd5fb0f9f6",
     "grade": true,
     "grade_id": "cell-a5776c997347476f",
     "locked": true,
     "points": 0.26,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model = TruncatedSVD(n_components=16, random_state=0)\n",
    "emb = model.fit_transform(A)\n",
    "\n",
    "operators = {\n",
    "    \"Average\": average_operator,\n",
    "    \"Hadamard product\": hadamard_operator,\n",
    "    \"Weighted L1\": weighted_l1_operator,\n",
    "    \"Weighted L2\": weighted_l2_operator,\n",
    "    \"Neighbor weighted L1\": neighbor_weighted_l1_operator,\n",
    "    \"Neighbor weighted L2\": neighbor_weighted_l2_operator\n",
    "}\n",
    "\n",
    "res = dict()\n",
    "for name, operator in operators.items():\n",
    "    lr = LogisticRegression()\n",
    "    train_emb = operator(G, emb, x_train)\n",
    "    lr.fit(train_emb, y_train)\n",
    "    test_emb = operator(G, emb, x_test)\n",
    "    y_pred = lr.predict_proba(test_emb)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    res[name] = {\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr\n",
    "    }\n",
    "\n",
    "assert auc(fpr, tpr) > 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "RsYeKdgQ3K-O",
    "outputId": "97f7bfc6-e6d9-4b21-aa85-2eeadef2a71b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for label, v in res.items():\n",
    "    fpr, tpr = v['fpr'], v['tpr']\n",
    "    plt.plot(fpr, tpr, lw=2, \n",
    "             label='{}, AUC={:.4f}'.format(label, auc(fpr, tpr)))\n",
    "plt.plot([0, 1], [0, 1], lw=2, linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
