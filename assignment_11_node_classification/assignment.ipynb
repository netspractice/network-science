{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80578bf",
   "metadata": {},
   "source": [
    "# Assignment — Node classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077f9a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, mean_squared_error, mutual_info_score, accuracy_score\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import requests\n",
    "from sklearn.cluster import k_means\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.metrics import balanced_accuracy_score, mean_squared_error, mutual_info_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350cb1d9",
   "metadata": {},
   "source": [
    "### Task 1. Assortativity analysis (0 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00901410",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/netspractice/network-science/main/datasets/569720_ego_pokec.gml'\n",
    "open('569720_ego_pokec.gml', 'wb').write(requests.get(url).content)\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/netspractice/network-science/main/datasets/musae_facebook_ego_802.gml'\n",
    "open('musae_facebook_ego_802.gml', 'wb').write(requests.get(url).content)\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/netspractice/network-science/main/datasets/polblogs.gml'\n",
    "open('polblogs.gml', 'wb').write(requests.get(url).content);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bdfcbd",
   "metadata": {},
   "source": [
    "If the structure of the network is known but the labels of the nodes are hidden, we would like to select a small subset of nodes such that, if we knew their labels, we could accurately predict the labels of all the other nodes. However, it makes sence if labels depend of network structure. A few next models work well upon the assumption of high assortativity mixing. Let us remind that assortative mixing is the tendency for nodes to be connected to other nodes that are like them in some way. Assortativity coefficient bounded by\n",
    "$$-1 \\leq r \\leq 1$$\n",
    "where $r \\to -1$ means that nodes tend to connect to nodes of the another class, $r \\to 1$ — to the same class. Therefore, randomly mixed networks show $r \\to 0$ for binary and numeric features, and $r < 0$ for categorical features.\n",
    "\n",
    "It is also useful to know stastical error of assortativity coefficient, that can be calculated by jackknife method\n",
    "$$\\sigma_{r}^{2}=\\sum_{i=1}^{M}\\left(r_{i}-r\\right)^{2}$$\n",
    "where $r_i$ is the value of $r$ for the network in which the $i$-th edge is removed.\n",
    "\n",
    "First, let us check assortativity coefficient for some networks and try to understand which labels can be predicted via network structure.\n",
    "\n",
    "Write a function `assortativity_coefficients` that takes a graph, an optional list of categorical (or binary) features, an optional list of numerical features. It returns two dictionaries where keys are features, values are:\n",
    "* assortativity coefficients\n",
    "* estimated standard deviation $\\sigma$\n",
    "\n",
    "_Use `nx.attribute_assortativity_coefficient` and `nx.numeric_assortativity_coefficient`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dd4846",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc5ce921056c789850c6eff145ceb8d1",
     "grade": false,
     "grade_id": "cell-5a7b9606f5363a00",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def assortativity_coefficients(G, categorical=[], numerical=[]):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792c037",
   "metadata": {},
   "source": [
    "Calculating standard deviation takes much time for large graphs. Here is a function that selects random connected subgraph to speed up the calculation in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f64df",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7d20965aec4a68527eb1d327e0369cf",
     "grade": false,
     "grade_id": "cell-b0c5f59f9c7653cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def random_subgraph(G, n_nodes):\n",
    "    np.random.seed(0)\n",
    "    nodes = set()\n",
    "    current_node = np.random.choice(G.nodes)\n",
    "    while len(nodes) < n_nodes:\n",
    "        next_node = np.random.choice(list(G.neighbors(current_node)))\n",
    "        nodes.add(next_node)\n",
    "        current_node = next_node\n",
    "    return G.subgraph(nodes).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe6a59f",
   "metadata": {},
   "source": [
    "Here is a subgraph of Slovakian online social network [Pokec](http://snap.stanford.edu/data/soc-Pokec.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6142c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c68fb47583d411bd1b143b6e50798322",
     "grade": true,
     "grade_id": "cell-fbebfac30bdf2aa3",
     "locked": true,
     "points": 0.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "G = nx.read_gml('569720_ego_pokec.gml')\n",
    "G = random_subgraph(G, 200)\n",
    "\n",
    "coef, std = assortativity_coefficients(\n",
    "    G, ['public', 'gender', 'region'], ['age', 'completion_percentage'])\n",
    "assert len(coef) == 5\n",
    "assert round(coef['gender'], 4) == 0.0453\n",
    "assert round(std['gender'], 4) == 0.0467\n",
    "assert std['region'] < std['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e69864",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'assortativity': coef, 'std': std}).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de255e5",
   "metadata": {},
   "source": [
    "* `public` is 1 if a person publishes his list of friends, and 0 otherwise\n",
    "* `gender` is 1 for male and 0 for female\n",
    "* `region` is a region of residence\n",
    "* `age` is integer age\n",
    "* `completion_percentage` is a percentage of completion information about a person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df6dc3",
   "metadata": {},
   "source": [
    "Next, look at a network of [political blogosphere in the 2004 US Election](http://www-personal.umich.edu/~mejn/netdata/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c71bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph(nx.read_gml('polblogs.gml'))\n",
    "G = random_subgraph(G, 100)\n",
    "coef, std = assortativity_coefficients(G, ['value', 'source'])\n",
    "pd.DataFrame({'assortativity': coef, 'std': std}).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f06f0c",
   "metadata": {},
   "source": [
    "The attribute `value` is political leaning that is divided into liberal and conservative. Also there is a category `source` where this information taken from.\n",
    "\n",
    "Next, look at subgraph of the [Facebook large page-page network](http://snap.stanford.edu/data/facebook-large-page-page-network.html) restricted to pages from 4 categories which are defined by Facebook. These categories are: politicians, governmental organizations, television shows and companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eba28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gml('musae_facebook_ego_802.gml')\n",
    "G = random_subgraph(G, 100)\n",
    "coef, std = assortativity_coefficients(G, ['value'])\n",
    "pd.DataFrame({'assortativity': coef, 'std': std}).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b050b1",
   "metadata": {},
   "source": [
    "Note that domain knowledge can help to preprocess the graph to get a higher assortativity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7203efe0",
   "metadata": {},
   "source": [
    "### Task 2. Relational neighbor classifier (0 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f1d99c",
   "metadata": {},
   "source": [
    "Now let us start again with the facebook dataset and try to predict a page category (0.78 assortativity coefficient): politicians, governmental organizations, television shows and companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ce2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gml('musae_facebook_ego_802.gml')\n",
    "G = nx.convert_node_labels_to_integers(G)\n",
    "len(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9db4430",
   "metadata": {},
   "source": [
    "Relational neighbor classifier is a simple probabilistic model for transductive semi-supervised learning on graphs. In contrast to *inductive* learning, *transductive* learning allows to use \"test\" set in training. Therefore, it is convinient to call train set as labeled set and test set as unlabeled set. \n",
    "* $X_L$ — labeled nodes\n",
    "* $X_U$ — unlabeled nodes\n",
    "* $Y_L$ — known labels\n",
    "* $Y_U$ — unknown labels (hidden from the model)\n",
    "\n",
    "Prepare labeled and unlabeled nodes to classification. Let us randomly select 30% of nodes as labeled nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5652de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "x_labeled = np.random.choice(G, size=int(0.3 * len(G)), replace=False)\n",
    "x_unlabeled = np.array(list(set(G.nodes).difference(x_labeled)))\n",
    "\n",
    "_labels = np.array(list(nx.get_node_attributes(G, 'value').values()))\n",
    "\n",
    "print(_labels[::300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd62fa16",
   "metadata": {},
   "source": [
    "Convert labels into integers for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e3986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = list(set(_labels))\n",
    "labels = np.array([unique.index(l) for l in _labels])\n",
    "y_labeled = labels[x_labeled]\n",
    "y_unlabeled = labels[x_unlabeled]\n",
    "print(labels[::300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7038c55",
   "metadata": {},
   "source": [
    "Let us denote $y_i$ as label of a node $i$. Relational Neighbor Classifier based on a simple iterative procedure\n",
    "\n",
    "$$P(y_i = c|\\mathcal N(i)) = \\frac{1}{Z}\\sum_{j \\in \\mathcal N(i)}A_{ij}P(y_j = c|\\mathcal N(j))$$\n",
    "\n",
    "where $Z$ is a normalizing constant, $\\mathcal N(i)$ is neighbors of node $i$. Note that this approach based on an assumption of strong assortativity — nodes related to each other are similar and likely belong to the same class. The algorithm is:\n",
    "\n",
    "1. Set an initial conditional distribution $P_0$. Labeled nodes have a probability one in truth class and zeros in others. Unlabeled nodes have an equal probability of each class.\n",
    "2. Update $P$ only for unlabeled nodes by the equation above\n",
    "3. Repeat 2 until converges: $\\Vert P_{i+1} - P_i \\Vert < \\varepsilon$\n",
    "4. Predictions are labels with maximal probability\n",
    "\n",
    "There is a function `relational_neighbor` that predicts labels. Parameters are:\n",
    "* `G`: graph\n",
    "* `threshold`: convergence threshold\n",
    "* `y_labeled`: np.array, labels for labeled nodes\n",
    "* `x_labeled`: np.array, labeled nodes\n",
    "* `x_unlabeled`: np.array, unlabeled nodes\n",
    "\n",
    "The function returns a np.array with labels for unlabeled nodes and np.array of norms of a distributions difference in each step before convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4856cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relational_neighbor(G, threshold, y_labeled, x_labeled, x_unlabeled):\n",
    "    cond = initial_conditional(G, y_labeled, x_labeled, x_unlabeled)\n",
    "    A = nx.to_numpy_array(G)\n",
    "    diffs = []\n",
    "    diff = np.inf\n",
    "    while diff > threshold:\n",
    "        next_cond = update_conditional(A, cond, x_labeled, x_unlabeled)\n",
    "        diff = np.linalg.norm(cond[x_unlabeled] - next_cond[x_unlabeled])\n",
    "        diffs.append(diff)\n",
    "        cond = next_cond\n",
    "    return np.argmax(cond[x_unlabeled], axis=1), diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ee940",
   "metadata": {},
   "source": [
    "Write a function `initial_conditional` that returns np.array with initial conditional distribution where $i$-th row represents probability of belonging of node $i$ to each class. Parameters are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d959ec4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab252152d48cc757aa89f90be60db3d7",
     "grade": false,
     "grade_id": "cell-6a324ac9fd641225",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def initial_conditional(G, y_labeled, x_labeled, x_unlabeled):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e2a0a1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "653a0e11bfe4e13a6555c79e710f9dba",
     "grade": true,
     "grade_id": "cell-8531b1de992d936c",
     "locked": true,
     "points": 0.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cond = initial_conditional(\n",
    "    G, y_labeled, x_labeled, x_unlabeled)\n",
    "assert cond.shape == (3873, 4)\n",
    "assert np.all(cond.sum(axis=1) == 1)\n",
    "assert np.all(cond[x_unlabeled] == 0.25)\n",
    "assert set(np.unique(cond[x_labeled])) == {0, 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0722ba08",
   "metadata": {},
   "source": [
    "Write a function `update_conditional` that updates and returns np.array with conditional distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1bf6aa",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c96c2585f9ce858e1d9fe360ba60eeb",
     "grade": false,
     "grade_id": "cell-ff6c82cd94e48f4d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def update_conditional(A, cond, x_labeled, x_unlabeled):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ccf903",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8c986fdc9160fdd406d119190ebe3c9",
     "grade": true,
     "grade_id": "cell-152e1da0674bfa21",
     "locked": true,
     "points": 0.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "A = nx.to_numpy_array(G)\n",
    "cond = update_conditional(\n",
    "    A, cond, x_labeled, x_unlabeled)\n",
    "assert cond.shape == (3873, 4)\n",
    "assert np.all(cond.sum(axis=1).round(4) == 1)\n",
    "assert set(np.unique(cond[x_labeled])) == {0, 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049bf13f",
   "metadata": {},
   "source": [
    "Check convergence of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ec25cb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da11e8bd11e7c82570bea9b435b6130b",
     "grade": true,
     "grade_id": "cell-08c28b32ff6cda6c",
     "locked": true,
     "points": 0.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred, diffs = relational_neighbor(\n",
    "    G, 0.001, y_labeled, x_labeled, x_unlabeled)\n",
    "score = balanced_accuracy_score(y_unlabeled, y_pred)\n",
    "assert len(diffs) < 40\n",
    "assert score > 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8846d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(diffs)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Difference')\n",
    "plt.title('Convergence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7caa2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Balanced accuracy:', round(score, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd6199d",
   "metadata": {},
   "source": [
    "For comparison, a random guess is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = balanced_accuracy_score(\n",
    "    y_unlabeled,\n",
    "    np.random.choice(range(4), size=len(x_unlabeled), replace=True)\n",
    ")\n",
    "print('Balanced accuracy:', round(score, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a972095d",
   "metadata": {},
   "source": [
    "### Task 3. Label propagation classifier (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e343ef76",
   "metadata": {},
   "source": [
    "Consider the label propagation algorithm on an artificial dataset consisting of 3 sinusoids with noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef78bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 600\n",
    "np.random.seed(0)\n",
    "x_space = np.linspace(0, 3 * np.pi, int(N/3))\n",
    "x1 = x_space + np.random.normal(0, 0.2, x_space.shape[0])\n",
    "y1 = np.sin(x_space) + np.random.normal(0, 0.2, x_space.shape[0])\n",
    "x2 = x_space + np.random.normal(0, 0.2, x_space.shape[0])\n",
    "y2 = np.sin(x_space) + np.random.normal(0, 0.2, x_space.shape[0]) - 1.3\n",
    "x3 = x_space + np.random.normal(0, 0.2, x_space.shape[0])\n",
    "y3 = np.sin(x_space) + np.random.normal(0, 0.2, x_space.shape[0]) - 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaecaaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = np.stack([np.concatenate([x1, x2, x3]), \n",
    "                        np.concatenate([y1, y2, y3])], axis=1)\n",
    "plt.scatter(data_points[:, 0], data_points[:, 1], \n",
    "            c=np.repeat(['tab:red', 'tab:orange', 'tab:green'], 200));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec155f32",
   "metadata": {},
   "source": [
    "Build a graph of k-neighbors of the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ea423",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = kneighbors_graph(data_points, n_neighbors=8)\n",
    "G = nx.Graph(A)\n",
    "pos = {i:loc for i, loc in enumerate(data_points)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6055e74",
   "metadata": {},
   "source": [
    "Select 20 random labeled nodes. The goal is to predict an index of the sinusoid for other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ff326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "x_labeled = np.random.choice(G, size=20, replace=False)\n",
    "x_unlabeled = np.array(list(set(range(N)).difference(x_labeled)))\n",
    "\n",
    "labels = np.array([0] * 200 + [1] * 200 + [2] * 200)\n",
    "y_labeled = labels[x_labeled]\n",
    "y_unlabeled = labels[x_unlabeled]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a058e05b",
   "metadata": {},
   "source": [
    "Draw the graph where train nodes are highlighted by colors with respect to a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ed22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.array([plt.cm.tab10(3), plt.cm.tab10(1), plt.cm.tab10(2)])\n",
    "\n",
    "node_color = colors[labels, :3]\n",
    "nx.draw(G, pos, node_size=50, width=0.5, linewidths=0.3, \n",
    "        edgecolors='black', node_color=node_color)\n",
    "plt.title('Ground truth labels')\n",
    "plt.show()\n",
    "\n",
    "node_color = np.ones((len(G), 3)) * 0.9\n",
    "node_color[x_labeled] = colors[y_labeled, :3]\n",
    "nx.draw(G, pos, node_size=50, width=0.5, linewidths=0.3, \n",
    "        edgecolors='black', node_color=node_color)\n",
    "plt.title('Labeled nodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d961534",
   "metadata": {},
   "source": [
    "Label propagation method is also assume that closer data points tend to have similar class labels. Let us denote $Y$ as given label matrix, whose $i$-th row representing the label probability distribution of node $i$. Initialization of rows corresponding to unlabeled data points is not important, but let it be a uniform distribution. The algorithm is\n",
    "1. Propagate $Y \\leftarrow PY$ where $P$ is a transition matrix\n",
    "2. Recover rows of $Y$ corresponding to labeled data points\n",
    "3. Row-normalize $Y$ to maintain probability\n",
    "4. Repeat 1-3 until $Y$ converges\n",
    "5. Make a prediction as the most likely labels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e35fee5",
   "metadata": {},
   "source": [
    "Here is a function `label_propagation` that returns predicted labels. Parameters are:\n",
    "* `G`: graph\n",
    "* `threshold`: convergence threshold\n",
    "* `y_labeled`: np.array, labels for labeled nodes\n",
    "* `x_labeled`: np.array, labeled nodes\n",
    "* `x_unlabeled`: np.array, unlabeled nodes\n",
    "\n",
    "The function returns a np.array with labels for unlabeled nodes and np.array of norms of a distributions difference in each step before convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a86687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_propagation(G, threshold, y_labeled, x_labeled, x_unlabeled):\n",
    "    y = initital_labels(G, y_labeled, x_labeled, x_unlabeled)\n",
    "    P = transition_matrix(G)\n",
    "    while True:\n",
    "        next_y = update_labels(P, y, y_labeled, x_labeled, x_unlabeled)\n",
    "        if np.linalg.norm(y - next_y) < threshold:\n",
    "            break\n",
    "        y = next_y\n",
    "    y_pred = np.argmax(y, axis=1)[x_unlabeled]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb64125",
   "metadata": {},
   "source": [
    "Write a function `initital_labels` that returns np.array with initial label matrix. Parameters are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eaf3ad",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ac1d314a8c6a34f9817a7b6cbb3a0cf",
     "grade": false,
     "grade_id": "cell-cd31c29674b345de",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def initital_labels(G, y_labeled, x_labeled, x_unlabeled):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751150b7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc23f7be42fa95d45c54abb4f36dd2d7",
     "grade": true,
     "grade_id": "cell-1a04c6f5b5d7fc54",
     "locked": true,
     "points": 1.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y = initital_labels(G, y_labeled, x_labeled, x_unlabeled)\n",
    "assert y.shape == (len(G), len(set(y_labeled)))\n",
    "assert np.all(y.sum(axis=1) == 1)\n",
    "assert y[x_labeled].max() == 1\n",
    "assert y[x_labeled].min() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea61626",
   "metadata": {},
   "source": [
    "Write a function `transition_matrix` that returns np.array with transition matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d97d8e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f521b5642f1380a572d2114a19462a6a",
     "grade": false,
     "grade_id": "cell-6ed1f2824e9c5ebe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def transition_matrix(G):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446bff77",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1c08e57882c952366265e2d2a98707a",
     "grade": true,
     "grade_id": "cell-0667369a810f6b0a",
     "locked": true,
     "points": 1.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "P = transition_matrix(G)\n",
    "assert P.shape == (len(G), len(G))\n",
    "assert np.all(P.sum(axis=1).round(4) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5abf1e",
   "metadata": {},
   "source": [
    "Write a function `update_labels` that returns np.array with updated label matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab47b0c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ddf3f967895906b51b5626d7ebd5826b",
     "grade": false,
     "grade_id": "cell-cade5b7096d69205",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def update_labels(P, y, y_labeled, x_labeled, x_unlabeled):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1545cd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "180f7ad40a174107da69f95ff988455f",
     "grade": true,
     "grade_id": "cell-0758fdb55082dda0",
     "locked": true,
     "points": 1.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "next_y = update_labels(P, y, y_labeled, x_labeled, x_unlabeled)\n",
    "assert next_y.shape == (len(G), len(set(y_labeled)))\n",
    "assert np.all(next_y.sum(axis=1).round(4) == 1)\n",
    "assert next_y[x_labeled].max() == 1\n",
    "assert next_y[x_labeled].min() == 0\n",
    "\n",
    "y_pred = label_propagation(G, 0.001, y_labeled, x_labeled, x_unlabeled)\n",
    "accuracy = accuracy_score(y_unlabeled, y_pred)\n",
    "assert accuracy > 0.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1749da",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.array([plt.cm.tab10(3), plt.cm.tab10(1), plt.cm.tab10(2)])\n",
    "node_color = np.ones((len(G), 3)) * 0.9\n",
    "node_color[x_unlabeled] = colors[y_pred, :3]\n",
    "\n",
    "nx.draw(G, pos, node_size=50, width=0.5, linewidths=0.3, \n",
    "        edgecolors='black', node_color=node_color)\n",
    "plt.title(f'Predicted labels, Accuracy: {accuracy:.4f}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a487dde",
   "metadata": {},
   "source": [
    "### Task 4. MultiRankWalk algorithm (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec8803f",
   "metadata": {},
   "source": [
    "MultiRankWalk is a semi-supervised learning method that based on random graph walk. Its basic component is similar to personalized PageRank\n",
    "\n",
    "$$r =\\alpha P^T r + (1 - \\alpha)v$$\n",
    "\n",
    "where $v$ is a teleportation vector and $P$ is a transition matrix. In this method, labeled instances of each class is described by a vector $v$, where each non-zero element corresponds to a labeled node. For each class $c$, at every time step the process may follow a transition with probability $\\alpha$ or it may decide to start the process again at an instance labeled $c$ with probability $1 − \\alpha$. The process is repeated for every class and the class of an unlabeled instance is decided by which class $c$’s process visited the instance most often. Let us check the algorithm on the karate club graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c17ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "x_labeled = np.array([32, 0, 1])\n",
    "x_unlabeled = np.array(list(set(G.nodes).difference(x_labeled)))\n",
    "labels = np.array([0 if G.nodes[n]['club'] == 'Mr. Hi' else 1 for n in G.nodes])\n",
    "y_labeled = labels[x_labeled]\n",
    "y_unlabeled = labels[x_unlabeled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d1b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.array([plt.cm.tab10(0), plt.cm.tab10(1)])\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "node_color = colors[labels, :3]\n",
    "nx.draw_kamada_kawai(G, node_size=200, width=0.5, linewidths=0.3, \n",
    "        edgecolors='black', node_color=node_color)\n",
    "plt.title('Ground truth labels')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "node_color = np.ones((len(G), 3)) * 0.9\n",
    "node_color[x_labeled] = colors[y_labeled, :3]\n",
    "nx.draw_kamada_kawai(G, node_size=200, width=0.5, linewidths=0.3, \n",
    "        edgecolors='black', node_color=node_color)\n",
    "plt.title('Labeled nodes');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a73f675",
   "metadata": {},
   "source": [
    "Here is a function `multirankwalk` that returns predicted labels. Parameters are:\n",
    "* `G`: graph\n",
    "* `y_labeled`: np.array, labels for labeled nodes\n",
    "* `x_labeled`: np.array, labeled nodes\n",
    "* `x_unlabeled`: np.array, unlabeled nodes\n",
    "\n",
    "The function returns a np.array with labels for unlabeled nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26711b83",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a536ef80ff223b5624392fb3c18e025e",
     "grade": false,
     "grade_id": "cell-e3c82919594881d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def multirankwalk(G, y_labeled, x_labeled, x_unlabeled, alpha):\n",
    "    n_classes = len(set(y_labeled))\n",
    "    y_pred = np.zeros((len(G), n_classes))\n",
    "    for c in range(n_classes):\n",
    "        y_pred[:, c] = personalized_pr(G, y_labeled, x_labeled, c, alpha)\n",
    "    return y_pred.argmax(axis=1)[x_unlabeled]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f4656",
   "metadata": {},
   "source": [
    "Write a function `personalized_pr` that takes mentioned parameters, a class label `c` and transition probability `alpha` and returns np.array with personalized page rank values for all nodes. *Use `nx.pagerank`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c059f1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5fb898e38e949e1fe4c3c004faaaef1e",
     "grade": false,
     "grade_id": "cell-6ab7ac5082af695a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def personalized_pr(G, y_labeled, x_labeled, c, alpha):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d025a9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc990dae15a38b1747e8d0214a5571bf",
     "grade": true,
     "grade_id": "cell-76a64366fdc0d113",
     "locked": true,
     "points": 3.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n_classes = len(set(y_labeled))\n",
    "y_pred = np.zeros((len(G), n_classes))\n",
    "y_pred_c = personalized_pr(G, y_labeled, x_labeled, c=0, alpha=0.8)\n",
    "assert y_pred_c.shape == (34,)\n",
    "assert np.all(y_pred_c.round(4)[:3] == [0.2115, 0.1682, 0.0592])\n",
    "y_pred_c = personalized_pr(G, y_labeled, x_labeled, c=1, alpha=0.8)\n",
    "assert np.all(y_pred_c.round(4)[:3] == [0.0354, 0.0241, 0.0472])\n",
    "y_pred = multirankwalk(G, y_labeled, x_labeled, x_unlabeled, alpha=0.8)\n",
    "accuracy = accuracy_score(y_unlabeled, y_pred)\n",
    "assert accuracy > 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c164bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.array([plt.cm.tab10(0), plt.cm.tab10(1)])\n",
    "node_color = np.ones((len(G), 3)) * 0.9\n",
    "node_color[x_unlabeled] = colors[y_pred, :3]\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "nx.draw_kamada_kawai(G, node_size=200, width=0.5, linewidths=0.3, \n",
    "        edgecolors='black', node_color=node_color)\n",
    "plt.title(f'Predicted labels, Accuracy: {accuracy:.4f}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734e1d3c",
   "metadata": {},
   "source": [
    "### Task 5. Ridge regression on graphs (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea4879",
   "metadata": {},
   "source": [
    "Consider node regression with Tikhonov ($L_2$, Ridge) regularization on an artificial dataset that was again converted into graph by k-neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae79188",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 600\n",
    "data_points, labels = make_moons(n_samples=N, noise=0.15, random_state=0)\n",
    "A = kneighbors_graph(data_points, n_neighbors=5).toarray()\n",
    "G = nx.Graph(A)\n",
    "pos = {i:loc for i, loc in enumerate(data_points)}\n",
    "\n",
    "np.random.seed(0)\n",
    "x_labeled = np.random.choice(G, size=20, replace=False)\n",
    "x_unlabeled = np.array(list(set(range(N)).difference(x_labeled)))\n",
    "labels[labels == 0] = 10\n",
    "labels[labels == 1] = 100\n",
    "y_labeled = labels[x_labeled]\n",
    "y_unlabeled = labels[x_unlabeled]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad562cdd",
   "metadata": {},
   "source": [
    "Here are labels of blue nodes equal to 10, reds equal to 100. Other labels are unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c11b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_color = np.ones((len(G), 3)) * 0.9\n",
    "node_color[labels == 10] = plt.cm.coolwarm(0)[:3]\n",
    "node_color[labels == 100] = plt.cm.coolwarm(255)[:3]\n",
    "nx.draw(G, pos, node_size=50, width=0.5, linewidths=0.3, \n",
    "        edgecolors='black', node_color=node_color)\n",
    "plt.title('Ground truth labels')\n",
    "plt.show()\n",
    "\n",
    "node_color = np.ones((len(G), 3)) * 0.9\n",
    "node_color[x_labeled[y_labeled == 10]] = plt.cm.coolwarm(0)[:3]\n",
    "node_color[x_labeled[y_labeled == 100]] = plt.cm.coolwarm(255)[:3]\n",
    "nx.draw(G, pos, node_size=50, width=0.5, linewidths=0.3, \n",
    "        edgecolors='black', node_color=node_color)\n",
    "plt.title('Labeled nodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fcb5fb",
   "metadata": {},
   "source": [
    "Consider given node labels $\\mathbf y$ and normalized labels\n",
    "\n",
    "$$\\tilde y_i = y_i - \\frac{1}{k}\\sum_{j=1}^k y_j$$ \n",
    "\n",
    "where $k$ is the number of known labels. Unknown labels are given as zeros. Let the function $\\mathbf f$ be predicted labels of nodes. One way to think about such a function is that it does not make too many “jumps” under high assortativity assumption. We formalize that notion, by the smoothness penalty\n",
    "\n",
    "$$\\sum_{i \\sim j} A_{i j}\\left(f_{i}-f_{j}\\right)^{2}=\\mathbf{f}^{T} L \\mathbf{f}$$\n",
    "\n",
    "where $L$ is the Laplacian. That is, the objective is to minimize the MSE between known labels and function $\\mathbf f$ plus the smoothness penalty $S = L^p$, where $p$ is an integer hyperparameter\n",
    "\n",
    "$$\\mathbf{\\tilde f} = \\text{argmin}_\\mathbf{f}\\left(\\frac{1}{k}\\sum_{i=1}^k(f_i - \\tilde y_i)^2 + \\gamma \\mathbf{f}^T S \\mathbf{f}\\right)$$\n",
    "\n",
    "The analytical solution is given as $\\mathbf{\\tilde f} = (k \\gamma S + I)^{-1}\\mathbf{\\tilde y}$ where $I$ is a diagonal matrix with ones and zeros. $I_{ii} = 1$ if a label of $i$-th node is known.\n",
    "\n",
    "_Remark: for the stability of the algorithm, we use $\\tilde y_i$ instead of $y_i$._\n",
    "\n",
    "Write a function `tikhonov_regularization` that takes coefficient of regularization, a power of Laplacian and returns predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86dd1a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7497dab8de60318c02ac4a36151a0ffc",
     "grade": false,
     "grade_id": "cell-83dad7d0900b8f54",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def tikhonov_regularization(G, gamma, y_labeled, x_labeled, x_unlabeled, p):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f616c81b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e54c6dd3e565930055c438de2bab2fd4",
     "grade": true,
     "grade_id": "cell-fa1ad892d4ee589e",
     "locked": true,
     "points": 4.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred = tikhonov_regularization(\n",
    "    G, 0.001, y_labeled, x_labeled, x_unlabeled, p=1)\n",
    "assert mean_squared_error(y_unlabeled, y_pred) < 282\n",
    "\n",
    "y_pred = tikhonov_regularization(\n",
    "    G, 0.001, y_labeled, x_labeled, x_unlabeled, p=2)\n",
    "assert mean_squared_error(y_unlabeled, y_pred) < 325"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c475e323",
   "metadata": {},
   "source": [
    "Let us see how penalty and power of Laplacian affect to predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a01fffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "for i, p in enumerate([1, 2]):\n",
    "    for j, gamma in enumerate([0.01, 0.5]):\n",
    "        y_pred = tikhonov_regularization(\n",
    "            G, gamma, y_labeled, x_labeled, x_unlabeled, p=p)\n",
    "        node_color = np.ones(len(G)) * y_labeled.mean()\n",
    "        node_color[x_unlabeled] = y_pred\n",
    "        mse = mean_squared_error(y_unlabeled, y_pred)\n",
    "        plt.subplot(2, 2, (i + 1) * i + j + 1)\n",
    "        nx.draw(G, pos, node_size=50, width=0.5, linewidths=0.3, \n",
    "                node_color=node_color, edgecolors='black', cmap=plt.cm.coolwarm)\n",
    "        plt.title(f'gamma: {gamma}, p: {p} \\nMSE: {mse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc416b2",
   "metadata": {},
   "source": [
    "### Task 6. SVD node embedding (0 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281a366d",
   "metadata": {},
   "source": [
    "Another way to classify nodes is to learn node embeddings and then use any supervised algorithm. One of the simplest way to obtain node embeddings is to apply SVD on adjacency matrix. The first step is to decompose the adjacency matrix $A$ into three matrices $U$\n",
    ", $S$ and $V$ so that \n",
    "\n",
    "$$USV^T = A$$\n",
    "\n",
    "Then we keep only $k$ first singular values, where $k$ is a number of dimensions of embedding. For example if $k=2$, then the 4x4 matrix $S$ is converted as follows\n",
    "\n",
    "$$S = \\begin{bmatrix}\n",
    "\\sigma_1 & 0 & 0 & 0 \\\\\n",
    "0 & \\sigma_2 & 0 & 0 \\\\\n",
    "0 & 0 & \\sigma_3 & 0 \\\\\n",
    "0 & 0 & 0 & \\sigma_4 \\\\\n",
    "\\end{bmatrix}\n",
    "\\Rightarrow\n",
    "\\begin{bmatrix}\n",
    "\\sigma_1 & 0 & 0 & 0 \\\\\n",
    "0 & \\sigma_2 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "And then we compute embeddings as $E = US$ and use only non-zero columns. Let us consider SVD embedding on the Zachary's Karate Club graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b24ac8f",
   "metadata": {},
   "source": [
    "Write a function `svd_adj` that takes a graph and returns 3 np.arrays with $U$, $S$, $V^T$ of an adjacency matrix. \n",
    "\n",
    "Hint: use `np.linalg.svd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0bc4c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1d72000a04f7d7610da540ef9e97f6b",
     "grade": false,
     "grade_id": "cell-9da3cd75a2c870cf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def svd_adj(G):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4afc54",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29cd49c992ce7caba8457166294bc603",
     "grade": true,
     "grade_id": "cell-9916cee422e7e71a",
     "locked": true,
     "points": 0.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "A = nx.to_numpy_array(G)\n",
    "u, s, vt = svd_adj(G)\n",
    "A_ = u @ s @ vt\n",
    "assert np.allclose(A, A_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3056adb",
   "metadata": {},
   "source": [
    "Write a function `svd_embedding` that takes np.arrays with $U$, $S$, a numer of dimensions $k$ and returns a np.array with node embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06598b8c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cebda4dc4d8f100434ebe7141675253c",
     "grade": false,
     "grade_id": "cell-b71bd633032058ce",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def svd_embedding(u, s, k):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc6038",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a85312a7fa6157185328b3cc06d2b15",
     "grade": true,
     "grade_id": "cell-db2be10d307ead94",
     "locked": true,
     "points": 0.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "attr = nx.get_node_attributes(G, 'club')\n",
    "attr = ['tab:orange' if i == 'Mr. Hi' else 'tab:blue' for i in list(attr.values())]\n",
    "\n",
    "G = nx.karate_club_graph()\n",
    "u, s, vt = svd_adj(G)\n",
    "\n",
    "emb = svd_embedding(u, s, 2)\n",
    "assert emb.shape == (34, 2)\n",
    "\n",
    "clf = LogisticRegression().fit(emb, attr)\n",
    "assert 0.97 < clf.score(emb, attr) < 1\n",
    "\n",
    "emb = svd_embedding(u, s, 8)\n",
    "assert emb.shape == (34, 8)\n",
    "\n",
    "clf = LogisticRegression().fit(emb, attr)\n",
    "assert clf.score(emb, attr) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f68a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = svd_embedding(u, s, 2)\n",
    "plt.scatter(emb[:, 0], emb[:, 1], c=attr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b2eb3a",
   "metadata": {},
   "source": [
    "As we see, SVD embeddings represent nodes in almost linearly seperable classes for the karate club graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d537590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
